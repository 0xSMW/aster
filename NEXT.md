# NEXT (2026-02-06): Aster Status + Handoff

This repo is mid-rewrite toward an assembly-first implementation of the Aster
language/toolchain. The current working system is an Aster0 subset compiler
(Python) plus a benchmark harness that hill-climbs performance against C++ and
Rust baselines. This document is the "pick up where we left off" state.

## Where We Are

- The old Rust workspace (`Cargo.toml`, `crates/*`) was removed; the active tree
  is now `asm/`, `aster/`, `tools/`, and `docs/`.
- Benchmark harness is functional and the primary objective function is the
  geometric mean of (Aster median / min(C++, Rust median)) across the suite.
- Latest recorded full-suite run in `BENCH.md`: **Run 048**, geometric mean
  **0.998x** (near parity overall).
- Filesystem benches are real-world and noisy (disk/cache state matters). The
  harness defaults attempt to align traversal strategies to reduce variance.

Read these first:
- `INIT.md`: production spec + long-term task tracker (compiler/runtime/stdlib).
- `BENCH.md`: chronological benchmark runs, deltas, and tuning notes.
- `AGENTS.md`: local repo notes (bench tracking, fs bench modes).

## Toolchain (Today)

### Aster0 compiler stub

`tools/build/asterc.py` compiles Aster0 sources for benchmarks.

Default pipeline:
- `ASTER_BACKEND=c` (default): Aster0 -> C (simple emitter) -> `clang -O3 -S` -> `.S`
- Cache: `.sha256` sidecar next to the `.S` output
  - enabled by default (`ASTER_CACHE=1`)
  - disable with `ASTER_CACHE=0`
- Timing: set `ASTER_TIMING=1` to print per-compile timing
  - current reality: `clang` dominates total compile time

Notes:
- There is an optional `ASTER_BACKEND=asm` mode for a small set of kernels that
  have templates (`dot/gemm/stencil/sort`). This is useful for micro-experiments,
  but by default the harness compiles Aster0 source via the C emitter to keep
  benchmark scoring honest.

### Benchmark harness

`tools/bench/run.sh`:
- builds Aster/C++/Rust executables into `tools/bench/out/`
- runs each bench multiple times, prints median/avg/stdev
- computes geometric mean ratio at the end

Bench sets:
- `BENCH_SET=kernels`: dot, gemm, stencil, sort, json, hashmap, regex, async_io
- `BENCH_SET=fswalk`: fswalk, treewalk, dircount, fsinventory
- default: kernels, plus fs benches if `FS_BENCH_ROOT` is set

## Running Benchmarks (Repro Commands)

Kernels only:
```bash
cd /path/to/aster
BENCH_SET=kernels tools/bench/run.sh
```

Filesystem benches (recommended pinned list mode + fixed dataset):
```bash
cd /path/to/aster
FS_BENCH_ROOT=$HOME \
FS_BENCH_MAX_DEPTH=5 \
FS_BENCH_LIST_FIXED=1 \
BENCH_SET=fswalk \
tools/bench/run.sh
```

Full suite:
```bash
cd /path/to/aster
FS_BENCH_ROOT=$HOME \
FS_BENCH_MAX_DEPTH=5 \
FS_BENCH_LIST_FIXED=1 \
tools/bench/run.sh
```

Outputs land in `tools/bench/out/`.

## Filesystem Bench Model (fswalk/treewalk/dircount/fsinventory)

Implementation files:
- Aster: `aster/bench/fswalk/fswalk.as`
- C++: `aster/bench/fswalk/cpp.cpp`
- Rust: `aster/bench/fswalk/rust.rs`

Modes:
- `fswalk`: list/replay mode (decouples traversal from metadata/stat)
  - list generated by `tools/bench/fswalk_list.sh`
  - harness pins to `tools/bench/data/fswalk_list.txt` when `FS_BENCH_LIST_FIXED=1`
- `treewalk`: live traversal
  - harness defaults to bulk mode (macOS `getattrlistbulk`) for Aster and C++
- `dircount`: live traversal count-only (skips byte accumulation)
- `fsinventory`: live traversal inventory (counts files/dirs/symlinks + hashes names)

Important env knobs (see `aster/bench/fswalk/README.md` for the full list):
- `FS_BENCH_TREEWALK_MODE=bulk|fts`
- `FS_BENCH_CPP_MODE=bulk|fts` (forces baseline traversal strategy)
- `FS_BENCH_BULK_BUF=<bytes>` (default: 8388608, i.e. 8 MiB)
- `FS_BENCH_PROFILE=1` (Aster prints bulk traversal timing breakdown)

Known macOS constraint:
- `getattrlistbulk` requires requesting `ATTR_CMN_RETURNED_ATTRS`; attempts to
  omit it to force a fixed record layout hit EINVAL.

## Latest Progress (What Was Changed Recently)

Benchmark-side work (kept because it helped overall or improved parity):
- Increased default bulk buffer to **8 MiB**:
  - Aster: `aster/bench/fswalk/fswalk.as` (`BULK_BUF_SIZE = 8388608`)
  - C++: `aster/bench/fswalk/cpp.cpp` (default env fallback now 8 MiB)
  - Docs: `aster/bench/fswalk/README.md`
- Added `fsinventory` benchmark:
  - wiring in `tools/bench/run.sh`
  - inventory hashing + symlink counting in Aster/C++/Rust implementations
- Hashmap kernel simplification:
  - Aster `aster/bench/hashmap/hashmap.as` switched to a simpler linear-probe
    map (fewer branches than prior robin-hood packed metadata).
- Experiments that regressed were reverted (important to avoid redoing them):
  - regex DFA/state machine regressed; reverted to pointer-scan
  - JSON 16-byte prescan regressed; reverted to 8-byte prescan
- Instrumentation added:
  - `FS_BENCH_PROFILE=1` for Aster bulk traversal breakdown
  - `ASTER_TIMING=1` prints `parse/emit/clang/total` ns in `tools/build/asterc.py`

## Latest Results Snapshot (Reference Point)

From `BENCH.md` Run 048 (full suite):
- geometric mean: **0.998x**
- remaining consistent-ish laggards in that run:
  - json: 1.125x
  - hashmap: 1.125x
  - async_io: 1.174x
  - dircount/fsinventory: ~1.02-1.04x

Filesystem results vary; always compare multiple runs and record stddev.

## Worktree State (Important)

`git status` currently shows:
- old Rust files deleted (`Cargo.toml`, `crates/*`, `rust-toolchain.toml`, etc.)
- new tree (`asm/`, `aster/`, `tools/`, `docs/`, `BENCH.md`) is present but not
  staged/committed yet

If you want a clean checkpoint for a new system, do a single "repo rewrite"
commit:
```bash
git add -A
git commit -m "Rewrite: assembly-first Aster toolchain + benchmark harness"
```

## Next Steps (Priority Order)

1. Fix C-emitter const correctness for `String` (low risk)
   - Current `tools/build/asterc.py` maps `String` to `char *`, which causes
     warnings when passing string literals (notably in JSON).
   - Goal: make non-mut string parameters `const char *` and keep explicitly
     mutable strings as `char *` (avoid breaking APIs that write into buffers).
   - After change: re-run full suite and only keep it if it doesn't regress
     (or if it measurably helps codegen/warnings).

2. Reduce IO benchmark variance + make comparisons stricter
   - Increase IO runs from 2 to 3 or 5 (env-controlled) and log medians/stdev in
     `BENCH.md`.
   - Standardize "replay list" support for treewalk/dircount/fsinventory (some
     list support exists already; make it first-class so traversal vs stat cost
     can be separated).

3. Close remaining kernel gaps (bench-driven, small diffs)
   - json: tighten the hot loop (branches and bounds checks); avoid large rewrites.
   - async_io: reduce syscall count and tighten the poll/read/write loop; confirm
     parity with baseline behavior.
   - hashmap: validate linear probing across repeated runs; if unstable, consider
     a control-byte style table (SwissTable-like) but keep it simple.

4. Build-time wins (clang dominates in `ASTER_TIMING`)
   - The current Aster0->C->clang pipeline will not win build-time metrics.
   - Path forward is either native assembly codegen for Aster0 (remove C+clang),
     or more aggressive caching/batching/incremental compilation.

5. Production language path (beyond benchmarks)
   - Continue assembly-first compiler work in `asm/compiler/` per `INIT.md`:
     aster_span, diagnostics, lexer, CST parser (recovery), AST/HIR/MIR, codegen.
   - Goal: retire the Python C-emitter and have Aster compile Aster.

## If You Only Do One Thing

Re-run the full suite with a fixed dataset and confirm we're still near Run 048.
Then start with `String` const-correctness in `tools/build/asterc.py` and re-bench.
